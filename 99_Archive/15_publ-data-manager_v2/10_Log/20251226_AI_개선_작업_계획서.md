---
created: 2025-12-26T1735
modified: 2025-12-26T1735
---
## Summary

데이터 흐름 최적화 검토 결과를 바탕으로 publ-data-manager v2의 개선 작업 계획 수립. P0 버그 수정부터 장기 리팩토링까지 4단계로 구분.

## Why (왜)

#### 배경

검토 결과 발견된 문제점:
- **P0**: 환불 상태 변경 시 is_refunded 미업데이트 (버그)
- **P1**: 에러 처리 부족, 중복 API 호출
- **P2**: 메모리 효율성, Linked Records 타이밍
- **P3**: 코드 중복

#### 목적

1. 데이터 정합성 버그 즉시 수정
2. 시스템 안정성 및 효율성 개선
3. 유지보수성 향상

## What (무엇을)

#### 작업 항목

---

## Phase 1: P0 버그 수정 (즉시)

### Task 1-1: 환불 상태 변경 시 is_refunded 업데이트

**파일:** `src/syncer.py`

**현재 코드 (라인 206-217):**
```python
# 상태 업데이트
if update_records:
    updated = 0
    for update in update_records:
        result = supabase.table(table_config['name']).update({
            'Refund Status': update['new_status']
        }).eq(table_config['unique_key'], update['order_number']).execute()
        if result.data:
            updated += 1
            print(f"  업데이트: {update['order_number']}: ...")
```

**수정 계획:**
```python
# 상태 업데이트 + is_refunded 처리
if update_records:
    updated = 0
    status_changed_to_refunded = []  # 추가

    for update in update_records:
        result = supabase.table(table_config['name']).update({
            'Refund Status': update['new_status']
        }).eq(table_config['unique_key'], update['order_number']).execute()

        if result.data:
            updated += 1
            # Refunded로 변경된 경우 수집
            if update['new_status'] == 'Refunded':
                status_changed_to_refunded.append(update['order_number'])

    # 상태 변경된 주문들의 is_refunded 업데이트
    if status_changed_to_refunded:
        print(f"\n상태 변경 → is_refunded 업데이트: {len(status_changed_to_refunded)}건")
        for order_number in status_changed_to_refunded:
            supabase.table(orders_table).update({
                'is_refunded': True
            }).eq('Order Number', order_number).execute()
```

**검증 방법:**
- [ ] 테스트 환불 레코드 생성 (Requested → Refunded)
- [ ] 동기화 실행 후 Orders.is_refunded 확인

---

## Phase 2: 안정성 개선 (단기)

### Task 2-1: 에러 재시도 로직 추가

**파일:** `src/syncer.py`, `src/airtable_syncer.py`

**작업 내용:**
1. 공통 재시도 유틸리티 함수 생성
2. 배치 삽입/업데이트에 재시도 적용
3. 부분 실패 시 실패 레코드 로깅

**새 파일:** `src/utils.py`
```python
import time
from functools import wraps

def retry_with_backoff(max_retries=3, base_delay=1):
    """지수 백오프 재시도 데코레이터"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise
                    delay = base_delay * (2 ** attempt)
                    print(f"  재시도 {attempt + 1}/{max_retries} ({delay}초 후)")
                    time.sleep(delay)
        return wrapper
    return decorator
```

---

### Task 2-2: 중복 Supabase 조회 제거

**파일:** `src/main.py`, `src/syncer.py`, `src/airtable_syncer.py`

**현재 흐름:**
```
sync_all() → Supabase 전체 조회 → 처리 → 데이터 버림
sync_all_to_airtable() → Supabase 전체 조회 (중복!)
```

**개선 흐름:**
```
sync_all() → Supabase 전체 조회 → 처리 → 데이터 반환
sync_all_to_airtable(cached_data) → 캐시된 데이터 사용
```

**수정 계획:**

`syncer.py` 수정:
```python
def sync_all():
    """전체 데이터 동기화 - 처리된 데이터도 반환"""
    # ... 기존 코드 ...

    # 마지막에 캐시된 데이터 반환
    cached_data = {
        'members': members_data,
        'orders': orders_data,
        'refunds': refunds_data
    }
    return results, cached_data
```

`main.py` 수정:
```python
# STEP 2
sync_results, cached_data = sync_all()

# STEP 3
airtable_results = sync_all_to_airtable(supabase, cached_data)
```

`airtable_syncer.py` 수정:
```python
def sync_all_to_airtable(supabase_client, cached_data=None):
    """캐시된 데이터가 있으면 사용, 없으면 조회"""
    if cached_data:
        members_data = cached_data['members']
        orders_data = cached_data['orders']
        refunds_data = cached_data['refunds']
    else:
        # 기존 조회 로직
        ...
```

---

## Phase 3: 효율성 개선 (중기)

### Task 3-1: 메모리 효율성 개선

**파일:** `src/syncer.py`

**현재 문제:**
- `get_existing_keys()`: 전체 키를 set에 저장
- 데이터 10만 건 이상 시 메모리 부족 가능

**개선 방안 A: 스트리밍 처리**
```python
def sync_members_streaming(supabase):
    """스트리밍 방식 - 배치 단위로 처리"""
    csv_data = read_csv_file(file_path)

    for batch_start in range(0, len(csv_data), 1000):
        batch = csv_data[batch_start:batch_start + 1000]
        batch_keys = [row['Member Code'] for row in batch]

        # 해당 배치의 키만 조회
        existing = supabase.table(...).select('Member Code').in_('Member Code', batch_keys).execute()
        existing_keys = {r['Member Code'] for r in existing.data}

        # 신규만 필터링 후 삽입
        new_records = [r for r in batch if r['Member Code'] not in existing_keys]
        if new_records:
            supabase.table(...).insert(new_records).execute()
```

**개선 방안 B: Upsert 사용**
```python
# 존재 여부 체크 없이 upsert
supabase.table(...).upsert(batch, on_conflict='Member Code').execute()
```

**권장:** 방안 B (Upsert) - 코드 단순화 + 성능 향상

---

### Task 3-2: Airtable Linked Records 타이밍 수정

**파일:** `src/airtable_syncer.py`

**현재 문제:**
```
1. Members 100개 신규 삽입
2. Orders 동기화 시작
3. existing_members 조회 (신규 100개 포함)
4. Orders 삽입... 근데 같은 배치 내 신규 Members는 record_id 없음
```

**수정 계획:**
```python
def sync_all_to_airtable(supabase_client, cached_data=None):
    # Members 동기화
    new_members = sync_members_to_airtable(api, members_data)

    # 신규 Members가 있으면 record_id 맵 갱신
    if new_members > 0:
        print("  신규 회원 추가됨 - Member ID 맵 갱신")
        # Orders 동기화 전에 최신 Members record_id 조회
        existing_members = get_existing_records(
            get_table(api, config.AIRTABLE_TABLES['members']),
            'Member Code'
        )
    else:
        existing_members = None  # 기존 로직 사용

    # Orders 동기화 (갱신된 existing_members 전달)
    sync_orders_to_airtable(api, orders_data, existing_members)
```

---

## Phase 4: 코드 품질 개선 (장기)

### Task 4-1: 공통 유틸리티 분리

**새 파일:** `src/utils.py`

```python
"""공통 유틸리티 모듈"""

def paginate_supabase(table, select='*', page_size=1000):
    """Supabase 페이지네이션 제너레이터"""
    offset = 0
    while True:
        result = table.select(select).range(offset, offset + page_size - 1).execute()
        if not result.data:
            break
        yield from result.data
        offset += page_size

def paginate_airtable(table):
    """Airtable 페이지네이션 제너레이터"""
    for record in table.all():
        yield record

def batch_process(items, batch_size, process_func):
    """배치 처리 유틸리티"""
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        process_func(batch)
```

---

### Task 4-2: 필드 매핑 설정 파일화

**파일:** `src/config.py`

```python
# 필드 매핑 정의
FIELD_MAPPINGS = {
    'members': {
        'supabase_to_airtable': {
            'Member Code': 'Member Code',
            'Username': 'Username',
            'E-mail': 'E-mail',
            # ...
        },
        'transforms': {
            'Birth year': lambda x: str(x) if x else '',
        }
    },
    'orders': {
        'supabase_to_airtable': {...},
        'transforms': {
            'Price': lambda x: int(str(x).replace(',', '').replace('원', '') or 0),
        }
    }
}

def map_record(record, mapping_type, table_name):
    """레코드 필드 매핑 유틸리티"""
    mapping = FIELD_MAPPINGS[table_name]
    result = {}
    for src, dest in mapping['supabase_to_airtable'].items():
        value = record.get(src, '')
        if src in mapping.get('transforms', {}):
            value = mapping['transforms'][src](value)
        result[dest] = value
    return result
```

---

## 리소스 산정

### 리소스 측정 기준

| 측정 항목 | 설명 | 단위 |
|-----------|------|------|
| 작업 시간 | AI 작업 + 검토/테스트 시간 | 분 |
| 토큰 사용량 | Claude API 예상 토큰 | K tokens |
| 코드 변경량 | Lines of Code (추가/수정/삭제) | LOC |
| 영향 범위 | 변경으로 영향받는 파일 수 | 파일 수 |
| 리스크 레벨 | 장애 발생 가능성 | 낮음/중간/높음 |
| 의존성 | 선행 작업 필요 여부 | Task ID |

---

### Phase 1: P0 버그 수정

#### Task 1-1: 환불 상태 변경 시 is_refunded 업데이트

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 15분 | 코드 수정 5분 + 테스트 10분 |
| **토큰 사용량** | ~5K | 단순 수정 작업 |
| **코드 변경량** | +15 LOC | syncer.py 추가 |
| **영향 범위** | 1 파일 | syncer.py |
| **리스크 레벨** | 낮음 | 기존 로직에 추가만 |
| **의존성** | 없음 | 독립 작업 |
| **테스트 항목** | 2개 | 상태 변경 시나리오 |

---

### Phase 2: 안정성 개선

#### Task 2-1: 에러 재시도 로직 추가

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 45분 | 신규 모듈 + 적용 + 테스트 |
| **토큰 사용량** | ~15K | 새 파일 생성 + 기존 파일 수정 |
| **코드 변경량** | +50 LOC (utils.py 신규), ~30 LOC 수정 | 총 ~80 LOC |
| **영향 범위** | 3 파일 | utils.py(신규), syncer.py, airtable_syncer.py |
| **리스크 레벨** | 중간 | 기존 함수 래핑 |
| **의존성** | 없음 | 독립 작업 |
| **테스트 항목** | 3개 | 재시도 동작, 최대 재시도 초과, 부분 실패 |

#### Task 2-2: 중복 Supabase 조회 제거

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 30분 | 인터페이스 변경 + 테스트 |
| **토큰 사용량** | ~12K | 3개 파일 수정 |
| **코드 변경량** | ~40 LOC 수정 | 함수 시그니처 + 호출부 변경 |
| **영향 범위** | 3 파일 | main.py, syncer.py, airtable_syncer.py |
| **리스크 레벨** | 중간 | 데이터 흐름 변경 |
| **의존성** | 없음 | 독립 작업 |
| **테스트 항목** | 2개 | 캐시 사용, 캐시 없이 fallback |

#### Phase 2 소계

| 항목 | 합계 |
|------|------|
| 총 작업 시간 | 75분 |
| 총 토큰 사용량 | ~27K |
| 총 코드 변경량 | ~120 LOC |
| 영향 파일 | 4개 (utils.py 신규 포함) |

---

### Phase 3: 효율성 개선

#### Task 3-1: 메모리 효율성 개선 (Upsert 전환)

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 60분 | 로직 재설계 + 충분한 테스트 |
| **토큰 사용량** | ~20K | 복잡한 로직 변경 |
| **코드 변경량** | -30 LOC, +20 LOC | 기존 로직 단순화 |
| **영향 범위** | 1 파일 | syncer.py |
| **리스크 레벨** | 높음 | 핵심 동기화 로직 변경 |
| **의존성** | Phase 1 완료 | is_refunded 로직 안정화 후 |
| **테스트 항목** | 5개 | 신규/기존/중복 데이터, 대량 데이터, 성능 비교 |

#### Task 3-2: Airtable Linked Records 타이밍 수정

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 30분 | 순서 조정 + 테스트 |
| **토큰 사용량** | ~10K | 단일 파일 수정 |
| **코드 변경량** | ~25 LOC 수정 | 함수 호출 순서 + 파라미터 추가 |
| **영향 범위** | 1 파일 | airtable_syncer.py |
| **리스크 레벨** | 중간 | Airtable 동기화에만 영향 |
| **의존성** | 없음 | 독립 작업 |
| **테스트 항목** | 2개 | 신규 회원+주문 동시 생성 시나리오 |

#### Phase 3 소계

| 항목 | 합계 |
|------|------|
| 총 작업 시간 | 90분 |
| 총 토큰 사용량 | ~30K |
| 총 코드 변경량 | ~75 LOC |
| 영향 파일 | 2개 |

---

### Phase 4: 코드 품질 개선

#### Task 4-1: 공통 유틸리티 분리

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 45분 | 리팩토링 + 기존 코드 교체 |
| **토큰 사용량** | ~15K | 새 모듈 + 기존 파일 수정 |
| **코드 변경량** | +60 LOC (utils.py), -40 LOC (중복 제거) | 순 +20 LOC |
| **영향 범위** | 3 파일 | utils.py, syncer.py, airtable_syncer.py |
| **리스크 레벨** | 낮음 | 기능 변경 없음 (리팩토링) |
| **의존성** | Task 2-1 | utils.py 이미 생성됨 |
| **테스트 항목** | 3개 | 회귀 테스트 |

#### Task 4-2: 필드 매핑 설정 파일화

| 항목 | 값 | 비고 |
|------|-----|------|
| **작업 시간** | 40분 | 설정 분리 + 매핑 함수 구현 |
| **토큰 사용량** | ~12K | config.py + airtable_syncer.py |
| **코드 변경량** | +40 LOC (config.py), -30 LOC (하드코딩 제거) | 순 +10 LOC |
| **영향 범위** | 2 파일 | config.py, airtable_syncer.py |
| **리스크 레벨** | 낮음 | 기능 변경 없음 |
| **의존성** | 없음 | 독립 작업 |
| **테스트 항목** | 3개 | 각 테이블 매핑 검증 |

#### Phase 4 소계

| 항목 | 합계 |
|------|------|
| 총 작업 시간 | 85분 |
| 총 토큰 사용량 | ~27K |
| 총 코드 변경량 | ~130 LOC (순 +30 LOC) |
| 영향 파일 | 4개 |

---

### 전체 리소스 요약

| Phase | 작업 시간 | 토큰 | LOC 변경 | 파일 수 | 리스크 |
|-------|-----------|------|----------|---------|--------|
| **Phase 1** | 15분 | 5K | +15 | 1 | 낮음 |
| **Phase 2** | 75분 | 27K | +120 | 4 | 중간 |
| **Phase 3** | 90분 | 30K | +75 | 2 | 높음 |
| **Phase 4** | 85분 | 27K | +30 | 4 | 낮음 |
| **총계** | **265분 (4.4시간)** | **~89K** | **~240 LOC** | **5개 (신규 1)** | - |

---

### 비용 추정

| 항목 | 산정 기준 | 예상 값 |
|------|-----------|---------|
| Claude API 비용 | ~89K tokens × $0.015/1K (output 기준) | ~$1.35 |
| 실행 시간 절감 | 중복 API 제거 시 | ~50% 감소 |
| 메모리 사용량 | Upsert 전환 시 | ~70% 감소 |

---

### ROI (투자 대비 효과)

| 개선 항목 | 투자 | 효과 |
|-----------|------|------|
| P0 버그 수정 | 15분 | 데이터 정합성 100% 보장 |
| 중복 API 제거 | 30분 | API 호출 50% 감소, 비용 절감 |
| Upsert 전환 | 60분 | 메모리 70% 절감, 대량 데이터 처리 가능 |
| 재시도 로직 | 45분 | 장애 복구율 향상 |

---

## 테스트 계획

### Phase 1 완료 후
- [ ] 환불 상태 변경 (Requested → Refunded) 시나리오 테스트
- [ ] Orders.is_refunded 정상 업데이트 확인

### Phase 2 완료 후
- [ ] 네트워크 오류 시뮬레이션 (재시도 동작 확인)
- [ ] API 호출 횟수 비교 (Before/After)
- [ ] 실행 시간 비교

### Phase 3 완료 후
- [ ] 대량 데이터 테스트 (10,000건 이상)
- [ ] 메모리 사용량 모니터링
- [ ] 신규 회원 + 신규 주문 동시 발생 시나리오

### Phase 4 완료 후
- [ ] 기존 기능 회귀 테스트
- [ ] 코드 커버리지 확인

---

## How (어떻게)

#### 진행 방법

1. Phase별 브랜치 생성 (feature/phase-1, feature/phase-2 등)
2. 각 Task 완료 후 테스트 → 커밋
3. Phase 완료 후 main 브랜치 병합
4. 다음 Phase 진행 전 운영 환경 모니터링

#### 진행 상태

예정 (Phase 1 즉시 착수 권장)
